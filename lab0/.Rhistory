N[n+1] = N[n] + Bh * N[n] - Dh * N[n]
AA[n+1] = N[n+1]*p[n+1]*(1-k*AA_m)
Aa[n+1] = N[n+1] * (1-p[n+1]- q[n+1])*(1-k*Aa_m)
aa[n+1] = N[n+1] *  q[n+1] *(1-chanceOfDeath) * (1-k*aa_m)
N[n+1] = AA[n+1] + Aa[n+1] + aa[n+1]
q[n+1] = AA[n+1]/N[n+1]
p[n+1] = aa[n+1]/N[n+1]
# - chanceOfDeath*P[n]
}
plot(aa, xlab = "Years", ylab = "Frequency or the growth of")
lines(AA)
log.reg2 <- glm(data = new_profile_dataset, new_status ~ age, family = "binomial")
#Load any required package
library(okcupiddata)
?profiles
head(profiles)
# visualize age
ggplot(data = profiles, mapping = aes(x = age, fill = status)) +
geom_histogram() +
xlim(15, 76)
library(ggplot2)
library(datasets)
library(dplyr)
head(profiles)
# visualize age
ggplot(data = profiles, mapping = aes(x = age, fill = status)) +
geom_histogram() +
xlim(15, 76)
# creating new status variable: assigned 1 to those who are married and 0 to those who are not married.
new_profile_dataset <- profiles %>%
mutate(new_status = (status == "married") * 1)
# view
head(new_profile_dataset)
log.reg2 <- glm(data = new_profile_dataset, new_status ~ age, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + ethnicity, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + income, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + income + body_type, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + income + drugs, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + diet, family = "binomial")
summary(log.reg2)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + education, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + job, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + location, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + offspring, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + orientation, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + speaks, family = "binomial")
summary(log.reg2)
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ sex, family = "binomial")
summary(log.reg2)
# Let's tidy up the dataset first
cleaned_profile_dataset <- na.omit(new_profile_dataset)
# log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + height + income + job + sex, family = "binomial")
#
# log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + height + income + job, family = "binomial")
#
# log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + height + income, family = "binomial")
#
# log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age + height, family = "binomial")
log.reg2 <- glm(data = cleaned_profile_dataset, new_status ~ age, family = "binomial")
summary(log.reg2)
ggplot(data = cleaned_profile_dataset, mapping = aes(x = new_status, y = age)) +
geom_boxplot()
ggplot(data = cleaned_profile_dataset, mapping = aes(age)) +
geom_boxplot()
ggplot(data = cleaned_profile_dataset, mapping = aes(age, x = status)) +
geom_boxplot()
ggplot(data = cleaned_profile_dataset, mapping = aes(y = age, x = new_status)) +
geom_boxplot()
ggplot(data = cleaned_profile_dataset, mapping = aes(y = age, x = status)) +
geom_boxplot()
ggplot(data = cleaned_profile_dataset, mapping = aes(y = age, x = status)) +
geom_boxplot()
log_reg <- glm(data = cleaned_data, ck_weather ~ female + age, family = "binomial")
#Load required packages
library(fivethirtyeight)
?weather_check
head(weather_check)
log_reg <- glm(data = cleaned_data, ck_weather ~ female + age, family = "binomial")
cleaned_data <- na.omit(weather_check)
log_reg <- glm(data = cleaned_data, ck_weather ~ female + age, family = "binomial")
summary(log_reg)
log_reg <- glm(data = cleaned_data, ck_weather ~ female, family = "binomial")
summary(log_reg)
ggplot(data = cleaned_profile_dataset, mapping = aes(y = age, x = status)) +
geom_boxplot()
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = new_status)) +
geom_bar(position = "fill")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = new_status)) +
geom_bar(position = "identity")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = status)) +
geom_bar(position = "status")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = status)) +
geom_bar(position = "status")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = cleaned_profile_dataset$status)) +
geom_bar(position = "status")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = cleaned_profile_dataset$status)) +
geom_bar()
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = status)) +
geom_bar(position = "fill", color = "white")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = new_status)) +
geom_bar(position = "fill", color = "white")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = new_status, fill = age)) +
geom_bar(position = "fill", color = "white")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = new_status, fill = age)) +
geom_bar(color = "white")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = new_status)) +
geom_bar(color = "white")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = new_status)) +
geom_bar(color = "white", position = fill)
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = new_status)) +
geom_bar(color = "white", position = "fill")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = new_status)) +
geom_bar(color = "white")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = status)) +
geom_bar(color = "white")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = status)) +
geom_bar(color = "white", position = "fill")
# proportion
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = new_status)) +
geom_bar(color = "white", position = "fill")
ggplot(data = cleaned_profile_dataset, mapping = aes(x = age, fill = as.character(new_status)))+
geom_bar(color = "white", position = "fill")
# It takes alot of time to run but shows up.
# qplot(predProb, destination, data = plot.data, geom = c('point', 'smooth'), method='loess') +
#         xlab("Predicted Probability") +
#         ylab("Destination (1 = US, 0 = not US) with jittering")
shiny::runApp('Desktop/47546a301aff402a902cd874ff1b297a')
server <- function(input, output, session) {
# Define a reactive expression for the document term matrix
terms <- reactive({
# Change when the "update" button is pressed...
input$update
# ...but not for anything else
isolate({
withProgress({
setProgress(message = "Processing corpus...")
getTermMatrix(input$selection)
})
})
})
# Make the wordcloud drawing predictable during a session
wordcloud_rep <- repeatable(wordcloud)
output$plot <- renderPlot({
v <- terms()
wordcloud_rep(names(v), v, scale=c(4,0.5),
min.freq = input$freq, max.words=input$max,
colors=brewer.pal(8, "Dark2"))
})
}
books <<- list("A Mid Summer Night's Dream" = "summer",
"The Merchant of Venice" = "merchant",
"Romeo and Juliet" = "romeo")
getTermMatrix <- memoise(function(book) {
# Careful not to let just any name slip in here; a
# malicious user could manipulate this value.
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.txt.gz", book),
encoding="UTF-8")
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, content_transformer(tolower))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
myDTM = TermDocumentMatrix(myCorpus,
control = list(minWordLength = 1))
m = as.matrix(myDTM)
sort(rowSums(m), decreasing = TRUE)
})
library("memoise")
install.packages("memoise")
install.packages("memoise")
shinyApp(ui = ui, server = server)
library(shiny)
library(shiny)
library(tm)
library(wordcloud)
library(memoise)
ui <- fluidPage(
# Application title
titlePanel("Word Cloud"),
sidebarLayout(
# Sidebar with a slider and selection inputs
sidebarPanel(
selectInput("selection", "Choose a book:",
choices = books),
actionButton("update", "Change"),
hr(),
sliderInput("freq",
"Minimum Frequency:",
min = 1,  max = 50, value = 15),
sliderInput("max",
"Maximum Number of Words:",
min = 1,  max = 300,  value = 100)
),
# Show Word Cloud
mainPanel(
plotOutput("plot")
)
)
)
# Text of the books downloaded from:
# A Mid Summer Night's Dream:
#  http://www.gutenberg.org/cache/epub/2242/pg2242.txt
# The Merchant of Venice:
#  http://www.gutenberg.org/cache/epub/2243/pg2243.txt
# Romeo and Juliet:
#  http://www.gutenberg.org/cache/epub/1112/pg1112.txt
server <- function(input, output, session) {
# Define a reactive expression for the document term matrix
terms <- reactive({
# Change when the "update" button is pressed...
input$update
# ...but not for anything else
isolate({
withProgress({
setProgress(message = "Processing corpus...")
getTermMatrix(input$selection)
})
})
})
# Make the wordcloud drawing predictable during a session
wordcloud_rep <- repeatable(wordcloud)
output$plot <- renderPlot({
v <- terms()
wordcloud_rep(names(v), v, scale=c(4,0.5),
min.freq = input$freq, max.words=input$max,
colors=brewer.pal(8, "Dark2"))
})
}
# The list of valid books
books <<- list("A Mid Summer Night's Dream" = "summer",
"The Merchant of Venice" = "merchant",
"Romeo and Juliet" = "romeo")
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(book) {
# Careful not to let just any name slip in here; a
# malicious user could manipulate this value.
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.txt.gz", book),
encoding="UTF-8")
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, content_transformer(tolower))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
myDTM = TermDocumentMatrix(myCorpus,
control = list(minWordLength = 1))
m = as.matrix(myDTM)
sort(rowSums(m), decreasing = TRUE)
})
shinyApp(ui = ui, server = server)
library(shiny)
library(tm)
library(wordcloud)
library(memoise)
ui <- fluidPage(
# Application title
titlePanel("Word Cloud"),
sidebarLayout(
# Sidebar with a slider and selection inputs
sidebarPanel(
selectInput("selection", "Choose a book:",
choices = books),
actionButton("update", "Change"),
hr(),
sliderInput("freq",
"Minimum Frequency:",
min = 1,  max = 50, value = 15),
sliderInput("max",
"Maximum Number of Words:",
min = 1,  max = 300,  value = 100)
),
# Show Word Cloud
mainPanel(
plotOutput("plot")
)
)
)
# Text of the books downloaded from:
# A Mid Summer Night's Dream:
#  http://www.gutenberg.org/cache/epub/2242/pg2242.txt
# The Merchant of Venice:
#  http://www.gutenberg.org/cache/epub/2243/pg2243.txt
# Romeo and Juliet:
#  http://www.gutenberg.org/cache/epub/1112/pg1112.txt
server <- function(input, output, session) {
# Define a reactive expression for the document term matrix
terms <- reactive({
# Change when the "update" button is pressed...
input$update
# ...but not for anything else
isolate({
withProgress({
setProgress(message = "Processing corpus...")
getTermMatrix(input$selection)
})
})
})
# Make the wordcloud drawing predictable during a session
wordcloud_rep <- repeatable(wordcloud)
output$plot <- renderPlot({
v <- terms()
wordcloud_rep(names(v), v, scale=c(4,0.5),
min.freq = input$freq, max.words=input$max,
colors=brewer.pal(8, "Dark2"))
})
}
# The list of valid books
books <<- list("A Mid Summer Night's Dream" = "summer",
"The Merchant of Venice" = "merchant",
"Romeo and Juliet" = "romeo")
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(book) {
# Careful not to let just any name slip in here; a
# malicious user could manipulate this value.
if (!(book %in% books))
stop("Unknown book")
text <- readLines(sprintf("./%s.txt.gz", book),
encoding="UTF-8")
myCorpus = Corpus(VectorSource(text))
myCorpus = tm_map(myCorpus, content_transformer(tolower))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
myDTM = TermDocumentMatrix(myCorpus,
control = list(minWordLength = 1))
m = as.matrix(myDTM)
sort(rowSums(m), decreasing = TRUE)
})
shinyApp(ui = ui, server = server)
runApp('Desktop')
install.packages("caret");
install.packages("kernlab")
library(caret);
library(kernlab);
data(spam);
head(spam)
library(caret);
library(kernlab);
data(spam);
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE);
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
dim(training)
library(caret);
library(kernlab);
data(spam);
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE);
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
dim(training)
modelFit <- train(type ~., data = training, method = "glm");
predictions <- predict(modelFit, newData = testing);
confusionMatrix(predictions, testing$type);
library(caret);
library(kernlab);
data(spam);
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE);
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
modelFit <- train(type~., data = training, method = "glm");
predictions <- predict(modelFit, newData = testing);
confusionMatrix(predictions, testing$type);
library(caret);
library(kernlab);
data(spam);
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE);
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
modelFit <- train(type ~., data = training, method = "glm");
predictions <- predict(modelFit, newData = testing);
confusionMatrix(predictions, testing$type);
library(caret);
library(kernlab);
data(spam);
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE);
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
modelFit <- train(type ~., data = training, method = "glm");
predictions <- predict(modelFit, newData = testing);
confusionMatrix(predictions, testing$type);
install.packages("httr")
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
library(httr)
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
library(httr)
page1 <- GET(url = "https://bennington-csm.symplicity.com/students/?signin_tab=0")
page1
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
library(httr)
page1 <- GET(url = "https://bennington-csm.symplicity.com/students/?signin_tab=0", authenticate("sadipgiri@bennington.edu", "SOS.0565"))
page1
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
library(httr)
page1 <- GET(url = "https://bennington-csm.symplicity.com/students/?signin_tab=0", authenticate("username", "password"))
page1
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
library(httr)
page1 <- GET(url = "https://bennington-csm.symplicity.com/students/?signin_tab=0", authenticate("sadipgiri@bennington.edu", "SOS.0565"))
page1
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
text <- readLines(url = "https://bennington-csm.symplicity.com/students/?signin_tab=0")
text
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
text <- readLines("https://bennington-csm.symplicity.com/students/?signin_tab=0")
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
library(httr)
page1 <- GET(url = "https://bennington-csm.symplicity.com/students/?signin_tab=0", authenticate("sadipgiri@bennington.edu", "SOS.0565"))
page1
install.packages("XML")
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
library(XML)
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
library(XML)
page1 <- xmlParse(file = "https://bennington-csm.symplicity.com/students/")
print(page1)
# Webscraping
# BEnnington College Worklink
# to statistically show why its all bullshits
# library(XML)
#
# page1 <- xmlParse(file = "https://bennington-csm.symplicity.com/students/")
# print(page1)
t <- readLines(url = "<a href="?mode=form&amp;id=8b99c6ebc0db9727fb8b00fa02ff71c0&amp;s=jobs&amp;ss=jobs" class="ListPrimaryLink">Administrative Intern</a>")
setwd("~/Desktop/DBMS/lab0")
my_file = read.csv("clean_CatalogDump.txt")
head(my_file)
my_file$Bib.Utility.No.[1]
dim(my_file)
sum(my_file$Total.Checkouts)
max(my_file$Total.Checkouts)
max(my_file$Last.Year.Circ)
type(my_file$Bib.Utility.No.)
